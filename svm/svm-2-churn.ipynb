{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines: Churn Analysis\n",
    "\n",
    "Let's look at a classification example in Spark MLLib.  We are going to look at some telecom data to see whether or not a customer \"churned\" or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = spark.read.csv(\"/data/churn/telco.csv.gz\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"read {:,} records\".format(dataset.count()))\n",
    "\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe show output is not easy to read\n",
    "# dataset.show()\n",
    "\n",
    "## pretty print with pandas\n",
    "## horizontally\n",
    "dataset.limit(10).toPandas()\n",
    "\n",
    "## vertically\n",
    "# dataset.limit(10).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Basic Analytics of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## describe\n",
    "\n",
    "## following output is hard to read\n",
    "# dataset.describe().show() \n",
    "\n",
    "## use pandas for pretty print\n",
    "## TODO : convert to pandas ('toPandas')\n",
    "dataset.describe().???().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Distribution by 'Churn'\n",
    "dataset.groupBy('???').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Distribution by 'ContraCT'\n",
    "dataset.groupBy('???').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Distribution by 'Gender'\n",
    "dataset.groupBy('???').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define columns\n",
    "prediction_column = ['Churn']\n",
    "categorical_columns = ['gender',  'InternetService','Contract','PaymentMethod']\n",
    "categorical_index = ['gender_index',  'InternetService_index','Contract_index','PaymentMethod_index']\n",
    "\n",
    "\n",
    "columns = ['SeniorCitizen','PhoneService','Partner','Dependents','tenure','MultipleLines',\n",
    "           'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',\n",
    "           'StreamingTV','StreamingMovies','PaperlessBilling',\n",
    "           'MonthlyCharges','TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.select(categorical_columns).show(5)\n",
    "dataset.select(prediction_column).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Deal with Categorical Columns\n",
    "\n",
    "Let's deal with the categorical columns, including the output\n",
    "\n",
    "Workflow:\n",
    "- **Feature Indexers** :  ( category columns --> '*_index' columns)\n",
    "- **Label indexer** : 'Churn' --> 'indexedLabel'\n",
    "- **Vector Assembler** : '*_index' columns --> 'features' \n",
    "- **Scaler** :  'features' --> 'scaledFeatures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## handy function to pretty print indexers, scalers, assemblers\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, StandardScaler, VectorAssembler, MinMaxScaler\n",
    "\n",
    "def pretty_print_transformer(transformer):\n",
    "    if (type(transformer) is StringIndexer) \\\n",
    "        or (type(transformer) is StandardScaler) \\\n",
    "        or (type(transformer) is MinMaxScaler) : \\\n",
    "        return (transformer.__class__.__name__ + \" : \" + transformer.getInputCol() + ' -> ' +  transformer.getOutputCol())\n",
    "    \n",
    "    if type(transformer) is VectorAssembler:\n",
    "        return (transformer.__class__.__name__ + \" : \" + str(transformer.getInputCols()) + ' -> ' +  transformer.getOutputCol())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 - Feature Indexers\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "print(\"indexing categorical columns : \", categorical_columnscategorical)\n",
    "\n",
    "## TODO : create indexers in a loop\n",
    "## loop through 'categorical_columns'\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid=\"keep\")\\\n",
    "            for column in ??? ]\n",
    "\n",
    "for indexer in indexers:\n",
    "    print(pretty_print_transformer(indexer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.2 - label indexer\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "## TODO : we need to index 'Churn' column too\n",
    "## Create a String Indexer with inputColumn='Churn' and outputCol='indexedLabel'\n",
    "labelIndexer = ???(inputCol=\"???\", outputCol=\"???\")\n",
    "\n",
    "print(pretty_print_transformer(labelIndexer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.3 - Vector assembler \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=columns + categorical_index, outputCol=\"features\")\n",
    "\n",
    "print (pretty_print_transformer(assembler))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.5 - Scaler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "## TODO : scale 'features' column into 'scaledFeatures'\n",
    "scaler = StandardScaler(inputCol=\"???\", outputCol=\"???\")\n",
    "\n",
    "print (pretty_print_transformer(scaler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Pipeline\n",
    "We are going to transform the data using Spark pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "##  with scaler\n",
    "stages = indexers + [labelIndexer, assembler,  scaler] \n",
    "\n",
    "## without scaler\n",
    "#stages = indexers + [assembler, labelIndexer] \n",
    "\n",
    "i = 0\n",
    "for stage in stages:\n",
    "    i = i+1\n",
    "    print (\"stage \", i , \" : \", pretty_print_transformer(stage))\n",
    "print()\n",
    "\n",
    "## TODO : Create a 'Pipeline' passing 'stages' as input\n",
    "pipeline = ???(stages=???)\n",
    "\n",
    "print (\"pipeline : \", pipeline.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## TODO : Run data through the pipeline\n",
    "## Hint : first call 'fit' and then 'transform'\n",
    "processed_data = pipeline.???(dataset).???(dataset)\n",
    "\n",
    "print (\"processed data count \", processed_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pretty print transformed data using pandas\n",
    "x = processed_data.limit(2).toPandas()\n",
    "# print horizontally\n",
    "# x\n",
    "# print veriticall\n",
    "x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Split into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : training=80%,  test=20%\n",
    "(training, test) = processed_data.randomSplit([???, ???])\n",
    "\n",
    "print(\"training set count : \", training.count())\n",
    "print(\"testing set count : \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Create SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "## TODO : create 'LinearSVC' model\n",
    "##    with labelCol='indexedLabel'\n",
    "##    with featuresCol='scaledFeatures'\n",
    "##    with maxIter=100\n",
    "lsvc = ???(labelCol=\"???\", featuresCol=\"???\", maxIter=???, regParam=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train  Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"training starting on \", training.count() , \" records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "## TODO : train the model\n",
    "## Hint :    call 'fit' on 'training' data\n",
    "lsvcModel = lsvc.???(???)\n",
    "print (\"training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for linearsSVC\n",
    "coef = lsvcModel.coefficients\n",
    "\n",
    "df = pd.DataFrame({'input' : columns + categorical_index, 'coefficient': lsvcModel.coefficients})\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "df\n",
    "#df.sort_values(by=['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"predicting on \" , test.count() , \" records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## TODO : predict on test data\n",
    "## Hint : 'transform' on 'test'\n",
    "predictions = lsvcModel.???(???)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: See the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 - AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='indexedLabel', rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)  #AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> What does AUC mean?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\\\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"accuracy \", accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 : Confusion matrix\n",
    "\n",
    "**Interpret the confusion matrix output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "predictions.groupBy('Churn').pivot('prediction', [0,1]).count().na.fill(0).orderBy('Churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 11: Try running without scaling features\n",
    "\n",
    "In Step-5  we are adding a scaler at the end to normalize the vector.  \n",
    "Try without scaler.  \n",
    "\n",
    "Uncomment the following line   \n",
    "```\n",
    "#stages = indexers + [assembler, featureIndexer, labelIndexer] \n",
    "```\n",
    "\n",
    "And run the whole notebook (Cell --> Run All)  \n",
    "Do you see any improvement/degradation in accuracy / AUC ?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
