{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines: College Admission\n",
    "\n",
    "Let's look at a classification example in Spark MLLib.  We looked at the college admission before. We can look again at this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/spark\n",
      "Spark config:\n",
      "\t spark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\texecutor.memory=2g\n",
      "\tspark.sql.warehouse.dir=/tmp/tmpfa_0xt3g\n",
      "\tsome_property=some_value\n",
      "Spark UI running on port 4042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-0-85.ec2.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ffbbcabf278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- admit: integer (nullable = true)\n",
      " |-- gre: integer (nullable = true)\n",
      " |-- gpa: double (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      "\n",
      "+-----+---+----+----+\n",
      "|admit|gre| gpa|rank|\n",
      "+-----+---+----+----+\n",
      "|    0|380|3.61|   3|\n",
      "|    1|660|3.67|   3|\n",
      "|    1|800| 4.0|   1|\n",
      "|    0|640|3.19|   4|\n",
      "|    0|520|2.93|   4|\n",
      "|    1|760| 3.0|   2|\n",
      "|    0|560|2.98|   1|\n",
      "|    0|400|3.08|   2|\n",
      "|    0|540|3.39|   3|\n",
      "|    1|700|3.92|   2|\n",
      "|    1|800| 4.0|   4|\n",
      "|    0|440|3.22|   1|\n",
      "|    1|760| 4.0|   1|\n",
      "|    1|700|3.08|   2|\n",
      "|    1|700| 4.0|   1|\n",
      "|    0|480|3.44|   3|\n",
      "|    1|780|3.87|   4|\n",
      "|    0|360|2.56|   3|\n",
      "|    1|800|3.75|   2|\n",
      "|    0|540|3.81|   1|\n",
      "+-----+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", header=True, inferSchema=True)\n",
    "dataset.printSchema()\n",
    "dataset.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.43</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.390699999999998</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>0.49756985195624304</td>\n",
       "      <td>124.46248065545332</td>\n",
       "      <td>0.3971877275408833</td>\n",
       "      <td>1.019803902718557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                admit                 gre                 gpa  \\\n",
       "0   count                  100                 100                 100   \n",
       "1    mean                 0.43               600.0   3.390699999999998   \n",
       "2  stddev  0.49756985195624304  124.46248065545332  0.3971877275408833   \n",
       "3     min                    0                 300                2.42   \n",
       "4     max                    1                 800                 4.0   \n",
       "\n",
       "                rank  \n",
       "0                100  \n",
       "1               2.52  \n",
       "2  1.019803902718557  \n",
       "3                  1  \n",
       "4                  4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe\n",
    "dataset.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|admit|count|\n",
      "+-----+-----+\n",
      "|    1|   43|\n",
      "|    0|   57|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see data spread\n",
    "dataset.groupBy(\"admit\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+-----+\n",
      "|admit|gre| gpa|rank|        features|label|\n",
      "+-----+---+----+----+----------------+-----+\n",
      "|    0|640|3.19|   4|[640.0,3.19,4.0]|    0|\n",
      "|    0|360|2.56|   3|[360.0,2.56,3.0]|    0|\n",
      "|    0|520| 2.9|   3| [520.0,2.9,3.0]|    0|\n",
      "|    0|660|3.34|   3|[660.0,3.34,3.0]|    0|\n",
      "|    1|800|3.73|   1|[800.0,3.73,1.0]|    1|\n",
      "|    0|480|3.39|   4|[480.0,3.39,4.0]|    0|\n",
      "|    0|580| 4.0|   2| [580.0,4.0,2.0]|    0|\n",
      "|    1|500| 3.6|   3| [500.0,3.6,3.0]|    1|\n",
      "+-----+---+----+----+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## TODO : input cols : gre, gpa, rank\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "featureVector.sample(False, 0.1, seed=10).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count  67\n",
      "testing set count  33\n"
     ]
    }
   ],
   "source": [
    "## Split into training and test\n",
    "## TODO: create training and test with an 80/20 split\n",
    "(training, test) = featureVector.randomSplit([80., 20.])\n",
    "\n",
    "print (\"training set count \", training.count())\n",
    "print (\"testing set count \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "## TODO : set MaxIter to 10\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starting...\n",
      "training done.\n",
      "CPU times: user 4 ms, sys: 8 ms, total: 12 ms\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model\n",
    "## TODO : fit on 'training' set\n",
    "print (\"training starting...\")\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print(\"training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs : gre, gpa, rank\n",
      "Coefficients: [0.003223278523069508,-0.2984123688790387,-0.3753747875232981]\n",
      "Intercept: -0.14612850609403052\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linearsSVC\n",
    "print (\"inputs : gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Iterations\n",
    "\n",
    "If any coefficient is zero, that variable won't be a factor in the decision !  \n",
    "Set **maxIter=50**  and try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the test set and get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|admit|gre| gpa|rank|        features|label|       rawPrediction|prediction|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|    0|380|2.91|   4|[380.0,2.91,4.0]|    0|[1.29116181085881...|       0.0|\n",
      "|    0|380|3.61|   3|[380.0,3.61,3.0]|    0|[1.12467568155084...|       0.0|\n",
      "|    0|440|2.48|   4|[440.0,2.48,4.0]|    0|[0.96944778085665...|       0.0|\n",
      "|    0|480|3.44|   3|[480.0,3.44,3.0]|    0|[0.75161772653445...|       0.0|\n",
      "|    0|500|3.17|   3|[500.0,3.17,3.0]|    0|[0.60658081647572...|       0.0|\n",
      "|    0|520|2.93|   4|[520.0,2.93,4.0]|    0|[0.84587106500666...|       0.0|\n",
      "|    0|560|2.42|   2|[560.0,2.42,2.0]|    0|[-0.1859999590910...|       1.0|\n",
      "|    0|560|3.19|   3|[560.0,3.19,3.0]|    0|[0.41915235246913...|       0.0|\n",
      "|    0|580|2.93|   2|[580.0,2.93,2.0]|    0|[-0.0982752214241...|       1.0|\n",
      "|    0|580|3.69|   1|[580.0,3.69,1.0]|    0|[-0.2468566085993...|       1.0|\n",
      "|    0|600|2.82|   4|[600.0,2.82,4.0]|    0|[0.55518342258440...|       0.0|\n",
      "|    1|500|3.13|   2|[500.0,3.13,2.0]|    1|[0.21926953419726...|       0.0|\n",
      "|    1|600| 3.4|   3| [600.0,3.4,3.0]|    1|[0.35288780901095...|       0.0|\n",
      "|    1|660|3.44|   2|[660.0,3.44,2.0]|    1|[-0.2039471951413...|       1.0|\n",
      "|    1|660|3.67|   3|[660.0,3.67,3.0]|    1|[0.24006243722412...|       0.0|\n",
      "|    1|680|3.85|   3|[680.0,3.85,3.0]|    1|[0.22931109316095...|       0.0|\n",
      "|    1|720|3.64|   1|[720.0,3.64,1.0]|    1|[-0.7130362202730...|       1.0|\n",
      "|    1|760|3.35|   3|[760.0,3.35,3.0]|    1|[-0.1777573731241...|       1.0|\n",
      "|    1|800| 4.0|   1| [800.0,4.0,1.0]|    1|[-0.8634700493221...|       1.0|\n",
      "|    1|800| 4.0|   4| [800.0,4.0,4.0]|    1|[0.26265431324777...|       0.0|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|admit|gre| gpa|rank|        features|label|       rawPrediction|prediction|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "|    0|380|3.61|   3|[380.0,3.61,3.0]|    0|[1.12467568155084...|       0.0|\n",
      "|    0|580|2.93|   2|[580.0,2.93,2.0]|    0|[-0.0982752214241...|       1.0|\n",
      "|    0|580|3.69|   1|[580.0,3.69,1.0]|    0|[-0.2468566085993...|       1.0|\n",
      "|    0|600|2.82|   4|[600.0,2.82,4.0]|    0|[0.55518342258440...|       0.0|\n",
      "|    1|660|3.44|   2|[660.0,3.44,2.0]|    1|[-0.2039471951413...|       1.0|\n",
      "|    1|680|3.85|   3|[680.0,3.85,3.0]|    1|[0.22931109316095...|       0.0|\n",
      "|    1|720|3.64|   1|[720.0,3.64,1.0]|    1|[-0.7130362202730...|       1.0|\n",
      "|    1|760|3.35|   3|[760.0,3.35,3.0]|    1|[-0.1777573731241...|       1.0|\n",
      "|    1|800| 4.0|   4| [800.0,4.0,4.0]|    1|[0.26265431324777...|       0.0|\n",
      "+-----+---+----+----+----------------+-----+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## TODO: transform the test data\n",
    "## HINT : test\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "predictions_test.show()\n",
    "\n",
    "## sample\n",
    "predictions_test.sampleBy(\"label\", fractions={0: 0.5, 1: 0.5}, seed=0).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: See the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lsvcModel.transform(test)  # Hint : test\n",
    "predictions_train = lsvcModel.transform(training)  # Hint : training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - Accuracy\n",
    "\n",
    "**TODO: Compare 'training' & 'test' set accuracies**  \n",
    "Can you detect any overfitting / underfitting?\n",
    "\n",
    "\n",
    "**TODO: Increase 'maxIterations' and try again**  \n",
    "Does the accuracy go up?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.7125\n",
      "Test accuracy : 0.6\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training accuracy :\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Test accuracy :\",  evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.2 - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|    0|  8|  3|\n",
      "|    1|  5|  4|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = predictions_test.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label')\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_pd = cm.toPandas()\n",
    "cm_pd.set_index(\"label\", inplace=True)\n",
    "# print(cm_pd)\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm_pd, annot=True, cmap=\"Blues\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - AUC\n",
    "**=> What does AUC mean?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for training:  0.7679028132992328\n",
      "AUC for test :  0.8181818181818181\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# default metrics for BinaryClassificationEvaluator is 'areaUnderCurve'\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "# print (\"default metrics : \" ,evaluator.getMetricName())\n",
    "\n",
    "print(\"AUC for training: \" , evaluator.evaluate(predictions_train))\n",
    "print (\"AUC for test : \" , evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Try running a prediction on your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gre  gpa  rank\n",
      "0  600  4.0     1\n",
      "1  700  3.5     2\n",
      "2  800  3.2     3\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "|gre|gpa|rank|       features|       rawPrediction|prediction|\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "|600|4.0|   1|[600.0,4.0,1.0]|[-0.2188143447082...|       1.0|\n",
      "|700|3.5|   2|[700.0,3.5,2.0]|[-0.3149735939313...|       1.0|\n",
      "|800|3.2|   3|[800.0,3.2,3.0]|[-0.3514503693787...|       1.0|\n",
      "+---+---+----+---------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "newdata = pd.DataFrame({'gre' : [600, 700, 800], \n",
    "                        'gpa' : [4.0, 3.5, 3.2],\n",
    "                        'rank': [1,   2,   3]}\n",
    "             )\n",
    "print(newdata)\n",
    "\n",
    "## TODO : create a spark dataframe\n",
    "## Hint : input is 'newdata'\n",
    "spark_newdata = spark.createDataFrame(newdata)\n",
    "\n",
    "## TODO : create feature vector\n",
    "## Hint : spark_newdata\n",
    "newfeatures = assembler.transform(spark_newdata)\n",
    "\n",
    "lsvcModel.transform(newfeatures).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Understanding the impact of Scaling Data\n",
    "Just now we have fed our input vector without scaling to SVM.  \n",
    "IN this section we are going to scale the data and see if it improves the prediction.  \n",
    "We will condense the code to focus on important stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 : Raw data (without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== run with raw data (not scaled) =======\n",
      "inputs :  gre, gpa, rank\n",
      "Coefficients: [0.004471158074653798,1.2161147145938713,-0.08283634499589466]\n",
      "Intercept: -6.953627550839707\n",
      "Training AUC :  0.8856951871657758\n",
      "Test AUC :  0.8376068376068375\n",
      "Training accuracy 0.7948717948717948\n",
      "Testing accuracy 0.8181818181818182\n",
      "===== END run with raw data (not scaled) =======\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "\n",
    "print (\"===== run with raw data (not scaled) =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "(training, test) = featureVector.randomSplit([0.8, 0.2], seed=123)\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='features')\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "predictions_train = lsvcModel.transform(training)\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"Training AUC : \" , evaluator.evaluate(predictions_train))\n",
    "print (\"Test AUC : \" , evaluator.evaluate(predictions_test))  #AUC\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Training accuracy\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Testing accuracy\",  evaluator.evaluate(predictions_test))\n",
    "print (\"===== END run with raw data (not scaled) =======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 : Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== run with scaled data  =======\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "|admit|gre|gpa |rank|features        |label|featuresScaled                                           |\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "|0    |380|3.61|3   |[380.0,3.61,3.0]|0    |[3.05312892687673,9.088901166082522,2.9417420270727606]  |\n",
      "|1    |660|3.67|3   |[660.0,3.67,3.0]|1    |[5.302802872996426,9.23996323532489,2.9417420270727606]  |\n",
      "|1    |800|4.0 |1   |[800.0,4.0,1.0] |1    |[6.427639846056274,10.070804616157918,0.9805806756909201]|\n",
      "|0    |640|3.19|4   |[640.0,3.19,4.0]|0    |[5.14211187684502,8.03146668138594,3.9223227027636804]   |\n",
      "|0    |520|2.93|4   |[520.0,2.93,4.0]|0    |[4.177965899936578,7.376864381335675,3.9223227027636804] |\n",
      "|1    |760|3.0 |2   |[760.0,3.0,2.0] |1    |[6.10625785375346,7.553103462118439,1.9611613513818402]  |\n",
      "|0    |560|2.98|1   |[560.0,2.98,1.0]|0    |[4.499347892239392,7.5027494390376495,0.9805806756909201]|\n",
      "|0    |400|3.08|2   |[400.0,3.08,2.0]|0    |[3.213819923028137,7.754519554441598,1.9611613513818402] |\n",
      "|0    |540|3.39|3   |[540.0,3.39,3.0]|0    |[4.3386568960879845,8.535006912193836,2.9417420270727606]|\n",
      "|1    |700|3.92|2   |[700.0,3.92,2.0]|1    |[5.62418486529924,9.86938852383476,1.9611613513818402]   |\n",
      "|1    |800|4.0 |4   |[800.0,4.0,4.0] |1    |[6.427639846056274,10.070804616157918,3.9223227027636804]|\n",
      "|0    |440|3.22|1   |[440.0,3.22,1.0]|0    |[3.535201915330951,8.106997716007125,0.9805806756909201] |\n",
      "|1    |760|4.0 |1   |[760.0,4.0,1.0] |1    |[6.10625785375346,10.070804616157918,0.9805806756909201] |\n",
      "|1    |700|3.08|2   |[700.0,3.08,2.0]|1    |[5.62418486529924,7.754519554441598,1.9611613513818402]  |\n",
      "|1    |700|4.0 |1   |[700.0,4.0,1.0] |1    |[5.62418486529924,10.070804616157918,0.9805806756909201] |\n",
      "|0    |480|3.44|3   |[480.0,3.44,3.0]|0    |[3.8565839076337642,8.66089196989581,2.9417420270727606] |\n",
      "|1    |780|3.87|4   |[780.0,3.87,4.0]|1    |[6.266948849904867,9.743503466132786,3.9223227027636804] |\n",
      "|0    |360|2.56|3   |[360.0,2.56,3.0]|0    |[2.892437930725323,6.445314954341068,2.9417420270727606] |\n",
      "|1    |800|3.75|2   |[800.0,3.75,2.0]|1    |[6.427639846056274,9.441379327648049,1.9611613513818402] |\n",
      "|0    |540|3.81|1   |[540.0,3.81,1.0]|0    |[4.3386568960879845,9.592441396890417,0.9805806756909201]|\n",
      "+-----+---+----+----+----------------+-----+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "inputs :  gre, gpa, rank\n",
      "Coefficients: [0.556491425374074,0.4830258399185652,-0.0844768279137541]\n",
      "Intercept: -6.95362755084178\n",
      "Training AUC :  0.8856951871657758\n",
      "Test AUC :  0.8376068376068375\n",
      "Training accuracy 0.7948717948717948\n",
      "Testing accuracy 0.8181818181818182\n",
      "===== END run with scaled data =======\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "print (\"===== run with scaled data  =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"featuresScaled\",\n",
    "                        withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(featureVector)\n",
    "fv_scaled = scalerModel.transform(featureVector)\n",
    "fv_scaled.show(20, truncate=False)\n",
    "\n",
    "(training, test) = fv_scaled.randomSplit([0.8, 0.2], seed=123)  ## CHANGED\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='featuresScaled')  ## CHANGED\n",
    "\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "predictions_train = lsvcModel.transform(training)\n",
    "predictions_test = lsvcModel.transform(test)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"Training AUC : \" , evaluator.evaluate(predictions_train))\n",
    "print (\"Test AUC : \" , evaluator.evaluate(predictions_test))  #AUC\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training accuracy\",  evaluator.evaluate(predictions_train))\n",
    "print(\"Testing accuracy\",  evaluator.evaluate(predictions_test))\n",
    "\n",
    "print (\"===== END run with scaled data =======\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Discuss the findings\n",
    "\n",
    "### Coefficients\n",
    "Here are the coefficients from one sample run\n",
    "\n",
    "raw data run : \n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.00730924862823,0.803788881405,-0.182571791707]\n",
    "Intercept: -7.016411699283878\n",
    "\n",
    "scaled data run:\n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.985025239033,0.311565356517,-0.180265498388]\n",
    "Intercept: -7.500693768967119\n",
    "\n",
    "### Accuracy\n",
    "Compare accuracies"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
