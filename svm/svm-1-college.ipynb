{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines: College Admission\n",
    "\n",
    "Let's look at a classification example in Spark MLLib.  We looked at the college admission before. We can look again at this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", header=True, inferSchema=True)\n",
    "dataset.printSchema()\n",
    "dataset.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use describe\n",
    "dataset.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see data spread\n",
    "dataset.groupBy(\"admit\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## TODO : input cols : gre, gpa, rank\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['???', '???', '???'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "featureVector.sample(False, 0.1, seed=10).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into training and test\n",
    "## TODO: create training and test with an 80/20 split\n",
    "(training, test) = featureVector.randomSplit([???, ???])\n",
    "\n",
    "print (\"training set count \", training.count())\n",
    "print (\"testing set count \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "## TODO : set MaxIter to 10\n",
    "lsvc = LinearSVC(maxIter=???, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "t1 = time.perf_counter()\n",
    "## TODO : fit on 'training' set\n",
    "lsvcModel = lsvc.fit(???training set???)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(\"traind on {:,} records in {:,.2f} ms\".\\\n",
    "      format(training.count(), (t2-t1)*1000))\n",
    "\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print (\"inputs : gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Iterations\n",
    "\n",
    "If any coefficient is zero, that variable won't be a factor in the decision !  \n",
    "Set **maxIter=50**  and try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the test set and get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = lsvcModel.transform(test)\n",
    "predictions.sample(False, 0.2).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: See the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 - AUC\n",
    "**=> What does AUC mean?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)  #AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 - Accuracy on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy\",  accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7.3 - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "predictions.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> TODO: What is the meaning of the confusion matrix?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase 'maxIterations' and try again\n",
    "In **Step-5** increase 'maxIter' to 50 and run again.  \n",
    "Does the accuracy go up?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 8: Try running a prediction on your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata = pd.DataFrame({'gre' : [600, 700, 800], \n",
    "                        'gpa' : [4.0, 3.5, 3.2],\n",
    "                        'rank': [1,   2,   3]}\n",
    "             )\n",
    "print(newdata)\n",
    "\n",
    "## TODO : create a spark dataframe\n",
    "## Hint : input is 'newdata'\n",
    "spark_newdata = spark.createDataFrame(???)\n",
    "\n",
    "## TODO : create feature vector\n",
    "## Hint : spark_newdata\n",
    "newfeatures = assembler.transform(???)\n",
    "\n",
    "lsvcModel.transform(newfeatures).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Understanding the impact of Scaling Data\n",
    "Just now we have fed our input vector without scaling to SVM.  \n",
    "IN this section we are going to scale the data and see if it improves the prediction.  \n",
    "We will condense the code to focus on important stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 : Raw data (without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "\n",
    "print (\"===== run with raw data (not scaled) =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "(training, test) = featureVector.randomSplit([0.8, 0.2], seed=123)\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='features')\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "predictions = lsvcModel.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)  #AUC\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy\",  accuracy)\n",
    "print (\"===== END run with raw data (not scaled) =======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 : Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "print (\"===== run with scaled data  =======\")\n",
    "dataset = spark.read.csv(\"/data/college-admissions/admission-data.csv\", \\\n",
    "                         header=True, inferSchema=True)\n",
    "assembler = VectorAssembler(inputCols=[ 'gre', 'gpa', 'rank'], outputCol=\"features\")\n",
    "featureVector = assembler.transform(dataset)\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"admit\"])\n",
    "\n",
    "# scaling\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"featuresScaled\",\n",
    "                        withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(featureVector)\n",
    "fv_scaled = scalerModel.transform(featureVector)\n",
    "fv_scaled.show(20, truncate=False)\n",
    "\n",
    "(training, test) = fv_scaled.randomSplit([0.8, 0.2], seed=123)  ## CHANGED\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0.3, featuresCol='featuresScaled')  ## CHANGED\n",
    "\n",
    "lsvcModel = lsvc.fit(training)\n",
    "print (\"inputs :  gre, gpa, rank\")\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))\n",
    "predictions = lsvcModel.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)  #AUC\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy\",  accuracy)\n",
    "print (\"===== END run with scaled data =======\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Discuss the findings\n",
    "\n",
    "### Coefficients\n",
    "Here are the coefficients from one sample run\n",
    "\n",
    "raw data run : \n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.00730924862823,0.803788881405,-0.182571791707]\n",
    "Intercept: -7.016411699283878\n",
    "\n",
    "scaled data run:\n",
    "inputs :  gre, gpa, rank\n",
    "Coefficients: [0.985025239033,0.311565356517,-0.180265498388]\n",
    "Intercept: -7.500693768967119\n",
    "\n",
    "### Accuracy\n",
    "Compare accuracies"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
