{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Naive Bayes Spam Filtering\n",
    "\n",
    "### Overview\n",
    "\n",
    "We all hate spam, so developing a classifier to classify email as spam or not spam is useful.  \n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20-30 minutes\n",
    "\n",
    "### Notes\n",
    "\n",
    "PySpark has a class called Linear Regression that can be used to do simple linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Let's load the dataframe\n",
    "\n",
    "We will load the dataframe into spark.  Since the outcome label is \"ham\" or \"spam\", we'll just call it label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "\n",
    "dataset = spark.read.format(\"csv\").option('header','true').option('delimiter', '\\t').\\\n",
    "  option('inferSchema', 'true').load(\"/data/spam/SMSSpamCollection.txt\")\n",
    "\n",
    "t2 = time.perf_counter() \n",
    "\n",
    "print(\"read {:,} records in {:,.2f} ms\".format(dataset.count(), (t2-t1)*1000))\n",
    "\n",
    "dataset.printSchema()\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count spam/ham\n",
    "dataset.groupby(\"isspam\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize using tf/idf\n",
    "\n",
    "Let's use tf/idf for vecorization at first.  TF/IDF will take and count the instances of each term, and then divide by the total frequecy of that term in the entire dataset.  \n",
    "\n",
    "This leads to very highly dimensional data, because every word in the document will lead to a dimension in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(dataset)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"isspam\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a numeric label out of the string column \"isspam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexer = StringIndexer(inputCol=\"isspam\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "indexed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into Training and Test\n",
    "\n",
    "We will split our dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "(train, test) = indexed.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "print(\"training set count : \", train.count())\n",
    "print(\"testing set count : \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "t1 = time.perf_counter()\n",
    "model = nb.fit(train)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(\"trained on {:,} records  in {:,.2f} ms\".\\\n",
    "      format(train.count(), (t2-t1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Test Data\n",
    "\n",
    "Let's call .transform on our model to do make predictions on our test data. The output should be contained in the \"prediction\" column, while the correct label will be there in the \"label\" column. \n",
    "\n",
    "We will be able to evaluate our results by comparing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Model\n",
    "\n",
    "Let's look at how our model performs.  We will do an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us do a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label').show()\n",
    "\n",
    "## Can you explain the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 7:  Your own test\n",
    "\n",
    "Now it's your turn!   Make a new dataframe with some sample test data of your own creation.  Make some \"spammy\" SMSes and some ordinary ones.  See how our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: make a dataframe with some of your own data.\n",
    "\n",
    "mydata = pd.DataFrame({'isspam' : ['spam', 'ham', ...],\n",
    "              'text' : ['My text here', 'My Text Here 2', ...]\n",
    "             })\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
