{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Multiple Linear Regression Lab : House Prices\n",
    "\n",
    "### Overview\n",
    "Estimate house prices using MLR\n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20 minutes\n",
    "\n",
    "### Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1 : House data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "housePrices = spark.read.csv(\"/data/house-prices/house-sales-full.csv\", \\\n",
    "                             header=True, inferSchema=True)\n",
    "print(\"read {:,} records\".format(housePrices.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housePrices.printSchema()\n",
    "housePrices.limit(5).toPandas().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! That's a lot of columns.  Maybe we should foucs on just a few of them.\n",
    "\n",
    "**=> Select only \"SalePrice\", \"Bedrooms\", \"Bathrooms\", \"SqFtTotLiving\", \"SqFtLot\" **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: select only \"SalePrice\", \"Bedrooms\", \"Bathrooms\", \"SqFtTotLiving\", \"SqFtLot\"\n",
    "housePrices_small = housePrices.select(\"???\", \"???\", \"???\", \"???\", \"???\")\n",
    "housePrices_small.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Features and Label Column in Dataframe\n",
    "\n",
    "We will create our \"features\" column, which is of type vector, and our label column, for which we can just reuse the SquareFootage column.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## TODO : Build features with  \"Bedrooms\", \"Bathrooms\", \"SqFtTotLiving\", \"SqFtLot\"\n",
    "## Hint : inputCols = ['Bedrooms', 'Bathrooms', ??? , ??? ]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[???], outputCol=\"features\")\n",
    "featureVector = assembler.transform(housePrices_small)\n",
    "\n",
    "## TODO : create a label column to mirror 'SalePrice'\n",
    "featureVector = featureVector.withColumn(\"label\", featureVector[\"???\"])\n",
    "featureVector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3: Run the Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "## Hint : Run model with max iterations as 10\n",
    "#lr = LinearRegression(maxIter=???)\n",
    "lr = LinearRegression(maxIter=???, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(featureVector)\n",
    "\n",
    "print(\"Coefficents:\" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insepct the coeffiients.  Are you seeing any ZERO (0) values?  What is the meaning of this?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"numIterations: %d\" % lrModel.summary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(lrModel.summary.objectiveHistory))\n",
    "# lrModel.summary.residuals.show()\n",
    "print(\"RMSE: %f\" % lrModel.summary.rootMeanSquaredError)\n",
    "\n",
    "## TODO : print 'r2' from training summary\n",
    "## Hint : Use TAB completion\n",
    "print(\"r2: %f\" % lrModel.summary.???)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the summary output\n",
    "- How many iterations did it do?\n",
    "- Is it more than our 'max' iterations?\n",
    "- If so, increase the 'maxIter' to 50 and run it again\n",
    "- How many iterations is done now?  \n",
    "- Can you explain the behavior?\n",
    "- Also did the coefficients change from  maxIter=10  to maxIter=50 ?\n",
    "- Did r2 change?  Why / Why-not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Predict some home prices\n",
    "Create a new data frame with the following data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make a Pandas dataframe\n",
    "new_data = pd.DataFrame({'Bedrooms' : [5,3,2],\n",
    "                         'Bathrooms' : [3,2,1.5],\n",
    "                         'SqFtTotLiving' : [4400, 1800, 1550],\n",
    "                         'SqFtLot' : [10000, 5000, 4000]\n",
    "             })\n",
    "\n",
    "new_data_spark = spark.createDataFrame(new_data)\n",
    "new_featureVector = assembler.transform(new_data_spark)  #run VectorAssembler again to create features.\n",
    "new_featureVector.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run on some prediction data\n",
    "\n",
    "Lets see the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: transform dataframe with new feature vector to get predictions\n",
    "## Hint : new_featureVector\n",
    "\n",
    "predicted_prices = lrModel.transform(???)\n",
    "predicted_prices.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Some more FUN\n",
    "Now let's feed 'SalePrice' as an input to our VectorAssembler.  \n",
    "In Step-2, try this\n",
    "\n",
    "```python\n",
    "assembler = VectorAssembler(inputCols=[\"SalePrice\", \"Bedrooms\", \"Bathrooms\", \"SqFtTotLiving\", \"SqFtLot\"],\n",
    "                            outputCol=\"features\")\n",
    "```\n",
    "\n",
    "Run again, and observe the following:\n",
    "- look at the coefficients  (why are most of them zero?)\n",
    "- look at r2\n",
    "\n",
    "Can you explain what is going on :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
