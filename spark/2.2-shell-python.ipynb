{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Lab 2.2 : Spark Shell\n",
    "\n",
    "### Overview\n",
    "Get familiar with Spark shell  \n",
    "\n",
    "## Step 1: Spark classes (sc & spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# older version spark context\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newwer Spark Session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the name of application name**\n",
    "print(sc.appName)\n",
    "\n",
    "# Find the 'Spark master' for the shell\n",
    "print(sc.master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Exploring Spark shell UI\n",
    "Spark shell UI is available on port 4040+\n",
    "\n",
    "The following code will print out the port number of Spark Shell UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In browser go to :   http://your_machine_address:port_number\n",
    "(use 'public' ip of machine)\n",
    "\n",
    "Here is a sample screen shot:\n",
    "\n",
    "<img src=\"../assets/images/2a.png\" style=\"border: 5px solid grey ; max-width:100%;\" />\n",
    "\n",
    "**==> Explore stage, storage, environment and executor tabs**\n",
    "\n",
    "**==> Take note of 'Event Timeline', we will use this for monitoring our jobs later**\n",
    "\n",
    "**==> Check spark master on port 8080,  Do you the Spark shell application connected?  Why (not)?**\n",
    "\n",
    "## STEP 3: Load a file\n",
    "We have data files under `spark-labs/data`.  \n",
    "Use test file :  `data/twinkle/sample.txt` .  \n",
    "The file has a favorite nursery rhyme\n",
    "\n",
    "```\n",
    "   twinkle twinkle little star\n",
    "   how I wonder what you are\n",
    "   up above the world so high\n",
    "   like a diamond in the sky\n",
    "   twinkle twinkle little star\n",
    "```\n",
    "\n",
    "Let's load the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala "
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = spark.read.text(\"/data/text/twinkle/sample.txt\")\n",
    "print(\"loaded file as \", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### answer the following questions:\n",
    "\n",
    "**==> Inspect Spark Shell UI on port 4040, do you see any processing done?  Why (not)?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## display the dataframe\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## display 10 lines, with truncate=False\n",
    "f.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## COunt of number of lines\n",
    "f.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print the first line / record from RDD\n",
    "## hint : f.first()\n",
    "f.???()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print first 3 lines\n",
    "f.take(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print all the content from the file\n",
    "## hint : collect\n",
    "f.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check out Jobs Page\n",
    "**==> Inspect the 'Jobs' section in Shell UI (in browser)**  \n",
    "Also inspect the event time line\n",
    "\n",
    "<img src=\"../assets/images/2b.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "\n",
    "\n",
    "**==> Inspect the 'Executor' section in Shell UI (in browser)**\n",
    "\n",
    "<img src=\"../assets/images/2c.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Running pyspark shell\n",
    "\n",
    "In a terminal start PySpark shell as follows:\n",
    "\n",
    "```bash\n",
    "$  PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"  ~/spark/bin/pyspark\n",
    "```\n",
    "\n",
    "And try the following commands in pyspark shell\n",
    "\n",
    "```python\n",
    "\n",
    "f = spark.read.text(\"/data/text/twinkle/sample.txt\")\n",
    "print(f.count())\n",
    "f.show(10, False)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6:  Connecting Shell and  Spark server\n",
    "\n",
    "For this lab, we are going use command line pyspark\n",
    "\n",
    "### 6.1 Start Spark Server\n",
    "If Spark server is not running, start it as\n",
    "\n",
    "```bash \n",
    "   $ ~/spark/sbin/start-all.sh\n",
    "```\n",
    "\n",
    "Use `jps` command to inspect the java process.  Your output might look like this.\n",
    "\n",
    "```\n",
    "    731 Master\n",
    "    902 Jps\n",
    "    831 Worker\n",
    "```\n",
    "\n",
    "Spark master UI is available on port 8080.\n",
    "In browser go to :   http://your_machine_address:8080\n",
    "(use 'public' ip of machine)\n",
    "\n",
    "Here is a sample screen shot:\n",
    "\n",
    "<img src=\"../assets/images/2d.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "\n",
    "### 6.2 Now start pyspark shell\n",
    "\n",
    "```bash\n",
    "   $ PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"   ~/spark/bin/pyspark\n",
    "```\n",
    "\n",
    "Once the shell starts, check the _server_ UI on port 8080.\n",
    "\n",
    "**==> Do you see the shell connected as an application?  why (not) ?**\n",
    "\n",
    "### 6.3 Connect Spark shell with the Spark server.\n",
    "Make a note of Spark server uri (e.g  `spark://host_name:7077`)\n",
    "\n",
    "**==> Restart spark shell as follows**\n",
    "\n",
    "```bash  \n",
    "  $   PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"   ~/spark/bin/pyspark   --master  spark-server-uri\n",
    "                                            ^^^^^^^^^^^^^^^^\n",
    "                                        update this to match your spark server\n",
    "\n",
    "  $   PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"   ~/spark/bin/pyspark   --master  spark://localhost:7077\n",
    "```\n",
    "\n",
    "On an Amazon server you may have to use the internal ip for the spark server, such as\n",
    "\n",
    "```bash\n",
    " $  PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"     ~/spark/bin/pyspark  --master spark://your_host_name:7077\n",
    "```\n",
    "\n",
    "On the ES VM you may have to use the localhost.localdomain. In all cases, follow what the spark master UI tells you.\n",
    "\n",
    "\n",
    "**==> Once the shell started, check both UIs**\n",
    "\n",
    "#### spark server UI at port 8080\n",
    "\n",
    "<img src=\"../assets/images/2e.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "---\n",
    "#### spark shell UI at  port 4040\n",
    "\n",
    "<img src=\"../assets/images/2f.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "\n",
    "\n",
    "\n",
    "## Tip : Dealing With Logs\n",
    "Spark Shell by default prints logs at warning (WARN) level.  If you want to change the logging level, do this at the pyspark shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to see any logs, you can start Spark shell as follows.  All the logs will be sent to 'logs' file.\n",
    "\n",
    "```bash\n",
    "   $  PYSPARK_PYTHON=python3  PYSPARK_DRIVER_PYTHON=\"python\"   ~/spark/bin/pyspark  2> logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS Lab 1 : Start multiple Shells\n",
    "* Using one terminal, start a shell and connect to master  using **Step 5.3**\n",
    "* Using second terminal (open one if you need to), start another shell connecting to the same master\n",
    "* Check the master UI (port 8080).  You would see some thing like this, can you explain the behavior?\n",
    "\n",
    "<img src=\"../assets/images/2g.png\" style=\"border: 5px solid grey ; max-width:100%;\" />\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
