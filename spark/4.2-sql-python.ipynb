{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Lab 4.2 : Spark SQL\n",
    "\n",
    "\n",
    "\n",
    "### Overview\n",
    "Using SQL statements with Spark SQL.   \n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20-30 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Load Clickstream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstreamDF = spark.read.json(\"/data/click-stream/clickstream.json\")\n",
    "print(clickstreamDF)\n",
    "clickstreamDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Register dataframe as a table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstreamDF.createOrReplaceTempView(\"clickstream\")\n",
    "print(\"created clickstream temp table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Querying using SQL\n",
    "\n",
    "\n",
    "**==> Select all logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs = spark.sql(\"select * from clickstream\")\n",
    "#'logs' is a dataframe\n",
    "\n",
    "# display the logs, hint : show\n",
    "logs.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Find records with only clicks**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find Records with only clicks\n",
    "# TODO: fix the  table name?\n",
    "spark.sql(\"select * from ???table_name??? where action = '???'\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Count records from each domain, sort the output by most to least**\n",
    "\n",
    "Sample output:\n",
    "\n",
    "```\n",
    "+-----------------+-----+\n",
    "|           domain|total|\n",
    "+-----------------+-----+\n",
    "|      nytimes.com|    1|\n",
    "|     facebook.com|    1|\n",
    "|       google.com|    2|\n",
    "|       amazon.com|    2|\n",
    "|    wikipedia.org|    3|\n",
    "+-----------------+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Try this query here:\n",
    "\n",
    "spark.sql(\"select domain, COUNT(*) as total from clickstream group by ???  order by ??? \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## STEP 3: Joining Datasets\n",
    "\n",
    "**==> Load `domains` dataset and register it to table `domains`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domainsDF = spark.read.json(\"/data/click-stream/domain-info.json\")\n",
    "domainsDF.show()\n",
    "domainsDF.createOrReplaceTempView(\"domains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Join `clickstreams` and `domains`**    \n",
    "Hint : Join query syntax for joining two tables A, B on A.x and A.y is\n",
    "```\n",
    "spark.sql(\"select A.*, B.* from A  join B  ON (A.x = B.y)\") \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "sql"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write sql query for joining clickstreams and domains\n",
    "# TODO : fill in the common attribute for  clickstream & domain table\n",
    "# Hint : domain\n",
    "\n",
    "s = \"\"\"\n",
    "SELECT clickstream.*, domains.*  \n",
    "from clickstream join domains \n",
    "ON (clickstream.???= domains.???)\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(s).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**==> Count traffic per domain category (news, social ..etc)**    \n",
    "Hint : query the joined datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Count traffic per domained category\n",
    "\n",
    "s = \"\"\"\n",
    "SELECT  domains.category, ???  \n",
    "from clickstream join domains \n",
    "ON (clickstream.???= domains.???)\n",
    "group by ???\n",
    "order by ??? \n",
    "\"\"\"\n",
    "\n",
    "spark.sql(s).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## STEP 4: Explore UI\n",
    "(Your DAG visualization may be slightly different from what we show here)\n",
    "\n",
    "<img src=\"../assets/images/5.2c.png\" style=\"border: 5px solid grey; max-width:100%;\"/>\n",
    "\n",
    "<img src=\"../assets/images/5.2d.png\" style=\"border: 5px solid grey; max-width:100%;\"/>\n",
    "\n",
    "<img src=\"../assets/images/5.2e.png\" style=\"border: 5px solid grey; max-width:100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Understand Query Execution\n",
    "We will use **explain** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from clickstream where cost > 100\").explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"join query here\").explain(extended=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
