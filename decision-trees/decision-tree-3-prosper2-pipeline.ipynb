{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Learning: Prosper Loan Dataset\n",
    "\n",
    "A decision tree a learned set of rules that allows us to make decisions on data.\n",
    "\n",
    "We are going to look at the prosper loan dataset.  This dataset shows a history of loans made by Prosper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"/data/prosper-loan/prosper-loan-data.csv.gz\", \n",
    "                         header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our columns for convenience.\n",
    "\n",
    "columns = ['Term', 'BorrowerRate', 'ProsperRating (numeric)', 'ProsperScore', 'EmploymentStatusDuration', 'IsBorrowerHomeowner',\n",
    "           'CreditScore', 'CurrentCreditLines', 'OpenCreditLines',\n",
    "           'TotalCreditLinespast7years', 'OpenRevolvingAccounts', 'OpenRevolvingMonthlyPayment',\n",
    "           'InquiriesLast6Months', 'TotalInquiries', 'CurrentDelinquencies', 'AmountDelinquent',\n",
    "           'DelinquenciesLast7Years', 'PublicRecordsLast10Years', 'PublicRecordsLast12Months',\n",
    "           'RevolvingCreditBalance', 'BankcardUtilization', 'AvailableBankcardCredit', 'TotalTrades',\n",
    "           'TradesNeverDelinquent (percentage)', 'TradesOpenedLast6Months', 'DebtToIncomeRatio',\n",
    "           'IncomeVerifiable', 'StatedMonthlyIncome', 'TotalProsperLoans', 'TotalProsperPaymentsBilled',\n",
    "           'OnTimeProsperPayments', 'ProsperPaymentsLessThanOneMonthLate', 'ProsperPaymentsOneMonthPlusLate',\n",
    "           'ProsperPrincipalBorrowed', 'ProsperPrincipalOutstanding', 'LoanOriginalAmount',\n",
    "           'MonthlyLoanPayment', 'Recommendations', 'InvestmentFromFriendsCount', 'InvestmentFromFriendsAmount',\n",
    "           'Investors', 'YearsWithCredit']\n",
    "\n",
    "categorical_columns = [\"BorrowerState\", \"EmploymentStatus\", \"ListingCategory\"]\n",
    "categorical_indexers = [\"BorrowerState_index\", \"EmploymentStatus_index\", \"ListingCategory_index\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.select(columns).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Examine the contents of the categorical columns.\n",
    "\n",
    "Let's look at the contents of our categorical columns.\n",
    "\n",
    "**=> TODO: Group by categorical columns BorrowerState, EmploymentStatus, ListingCategory**\n",
    "**and see the breakdowns by count** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupBy('LoanStatus').count().show()\n",
    "dataset.groupBy('BorrowerState').count().show()\n",
    "dataset.groupBy('EmploymentStatus').count().show()\n",
    "dataset.groupBy('ListingCategory').count().show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> What does that say about the cardinality of these categorical columns? ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Converting Categorical columns \n",
    "\n",
    "We need to convert categorical columns to numerics.  Remember, remember, Spark ML can *only* handle numeric columns.  There's a tool called StringIndexer that will help us here.\n",
    "\n",
    "Because there are a lot of indexers, we build a pipeline to help us out here. \n",
    "\n",
    "**=> TODO: enter in the list with all of our indexers into the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"keep\").\\\n",
    "            fit(dataset) for column in categorical_columns ]\n",
    "\n",
    "print(len(indexers))\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(dataset).transform(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Drop all NAs.\n",
    "\n",
    "We're just going to drop NAs.\n",
    "\n",
    "**=> TODO: Drop all NAs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na_dropped = df_r.select(columns + categorical_indexers + ['LoanStatus']).na.drop() #TODO: Drop NAs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build feature vectors using VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=columns + categorical_indexers, outputCol=\"features\")\n",
    "fv = assembler.transform(na_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build Indexers\n",
    "\n",
    "We are going to load the label indexer, which will make us a label column for loan status.\n",
    "We will also add feature indexer which will identify which features are categorical. (we should have 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"LoanStatus\", outputCol=\"indexedLabel\").fit(fv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=2000).fit(fv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split Data into training and test.\n",
    "\n",
    "We will split our the data up into training and test.  (You know the drill by now).\n",
    "\n",
    "**=> TODO: Split dataset into 70% training, 30% validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) =  fv.randomSplit([.7,.3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run the pipeline that will fit our decision tree\n",
    "\n",
    "We have a 3 stage pipeline here: \n",
    "\n",
    " 1. LabelIndexer\n",
    " 2. FeatureIndexer\n",
    " 3. DecisionTreeClassifier\n",
    " \n",
    "Running the pipeline will do all three.  Note that our other indexer pipeline already ran above.\n",
    "\n",
    "**=> TODO: Add labelIndexer, featureIndexer, and dt to our pipeline**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxBins=5000)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate the model.\n",
    "\n",
    "Let us check to see how the model did, using accuracy as a measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy \",   accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
