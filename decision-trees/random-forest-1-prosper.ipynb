{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest : Prosper Loan Dataset\n",
    "\n",
    "A decision tree a learned set of rules that allows us to make decisions on data.\n",
    "\n",
    "We are going to look at the prosper loan dataset.  This dataset shows a history of loans made by Prosper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## small file, start with this\n",
    "datafile = \"/data/prosper-loan/prosper-loan-data-sample.csv\"\n",
    "\n",
    "## this is a large file\n",
    "#datafile = \"/data/prosper-loan/prosper-loan-data.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = spark.read. \\\n",
    "          option(\"header\", \"true\"). \\\n",
    "          option(\"inferSchema\", \"true\").  \\\n",
    "          csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"read {:,} records\".format(data.count()))\n",
    "# schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print with pandas\n",
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## select a few columns \n",
    "## start with: 'LoanStatus',  'EmploymentStatus', 'CreditScore', 'StatedMonthlyIncome'\n",
    "## we add more later\n",
    "\n",
    "select_columns = ['LoanStatus',  'ProsperScore', 'EmploymentStatus', 'CreditScore', 'StatedMonthlyIncome', 'ListingCategory']\n",
    "\n",
    "## Note : vector columns can only have Numbers, don't include Categorical columns here\n",
    "## And dfefinitely not 'LoanStatus'  (if you are curiuos include and see what happens!)\n",
    "vector_columns = [  'ProsperScore', 'EmpIndex', 'CreditScore', 'StatedMonthlyIncome']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Display\n",
    "\n",
    "prosper = data.select(select_columns)  \n",
    "prosper.printSchema()\n",
    "\n",
    "prosper.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop any NA values.  Using `dataframe.na.drop()`\n",
    "prosper_clean = prosper.na.drop()\n",
    "print(\"Original record count {:,}, cleaned records count {:,},  dropped {:,}\"\\\n",
    "      .format(prosper.count(), prosper_clean.count(), (prosper.count() - prosper_clean.count())))\n",
    "prosper_clean.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prosper_clean.groupBy('LoanStatus').count().show()\n",
    "prosper_clean.groupBy('EmploymentStatus').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> What does that say about the cardinality of these categorical columns? ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Converting Categorical columns \n",
    "\n",
    "Convert categorical columns to numeric.   \n",
    "Here let's convert **EmploymentStatus** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "strIndexer_employment = StringIndexer(inputCol=\"EmploymentStatus\", outputCol=\"EmpIndex\")\n",
    "prosper_indexed = strIndexer_employment.fit(prosper_clean).transform(prosper_clean)\n",
    "\n",
    "prosper_indexed.limit(10).toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build feature vectors using VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=vector_columns, outputCol=\"features\")\n",
    "feature_vector = assembler.transform(prosper_indexed)\n",
    "feature_vector = feature_vector.withColumn(\"label\", feature_vector[\"LoanStatus\"])\n",
    "\n",
    "feature_vector.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into training and test.\n",
    "\n",
    "We will split our the data up into training and test.  (You know the drill by now).\n",
    "\n",
    "**=> TODO: Split dataset into 70% training, 30% validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(training, test) =  feature_vector.randomSplit([???,???])\n",
    "print(\"training set = \" , training.count())\n",
    "print(\"testing set = \" , test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-853b20f21adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## TODO : Create a RandomForest with numTrees=20  and maxBins=10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# rf = RandomForestRegressor(labelCol=\"label\", featuresCol=\"features\", \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "## TODO : Create a RandomForest with numTrees=20  and maxBins=10000\n",
    "\n",
    "# rf = RandomForestRegressor(labelCol=\"label\", featuresCol=\"features\", \\\n",
    "#                             numTrees=20, maxBins=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print (\"training starting...\")\n",
    "## TODO : train in training data\n",
    "rf_model = rf.fit(???)\n",
    "print (\"training done.\")\n",
    "\n",
    "## TODO : NOtice the time it took for training\n",
    "## Is it more or less than decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Print RF\n",
    "**==>Q : How many nodes the tree has?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## print the model\n",
    "print(rf_model)\n",
    "print()\n",
    "print(rf_model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Create Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : predict on test data\n",
    "predictions = rf_model.transform(???)\n",
    "\n",
    "predictions2= predictions.drop('rawPrediction', 'probability')\n",
    "predictions2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model.\n",
    "\n",
    "Let us check to see how the model did, using accuracy as a measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = rf_model.transform(???)  # Hint : test\n",
    "predictions_train = rf_model.transform(???)  # Hint : training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "print(\"Training set accuracy = \" , evaluator.evaluate(predictions_train))\n",
    "print(\"Test set accuracy = \" , evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is RF more stable than DTs ?\n",
    "Do a few runs, and see the accuracy above.   \n",
    "Does it vary a lot like Decision Trees before?   \n",
    "Probably not.  Why do you think it is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = predictions_test.groupBy('LoanStatus').pivot('prediction', [0,1]).count().na.fill(0).orderBy('LoanStatus')\n",
    "cm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_pd = cm.toPandas()\n",
    "cm_pd.set_index(\"LoanStatus\", inplace=True)\n",
    "# print(cm_pd)\n",
    "\n",
    "# colormaps : cmap=\"YlGnBu\" , cmap=\"Greens\", cmap=\"Blues\",  cmap=\"Reds\"\n",
    "sns.heatmap(cm_pd, annot=True, fmt=',', cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 - AUC\n",
    "\n",
    "For scewed data 'Area Under Precision Recall' curve might be better indicator.  \n",
    "https://stats.stackexchange.com/questions/90779/area-under-the-roc-curve-or-area-under-the-pr-curve-for-imbalanced-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# default metrics for BinaryClassificationEvaluator is 'areaUnderCurve'\n",
    "evaluator1 = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName='areaUnderROC')\n",
    "\n",
    "print(\"AUC for training: \" , evaluator1.evaluate(predictions_train))\n",
    "print (\"AUC for test : \" , evaluator1.evaluate(predictions_test))\n",
    "\n",
    "evaluator2 = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName='areaUnderPR')\n",
    "print(\"Area under PR for training: \" , evaluator2.evaluate(predictions_train))\n",
    "print (\"Area under PR for test : \" , evaluator2.evaluate(predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Improve Accuracy\n",
    "\n",
    "### Add more data\n",
    "In Step-1 change the 'datafile' to the full dataset.  \n",
    "And see how the accuracy above changes\n",
    "\n",
    "### Add more features\n",
    "Look at the schema of the full dataset.  Are there any columns you want to add"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
