{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest : Prosper Loan Dataset\n",
    "\n",
    "A decision tree a learned set of rules that allows us to make decisions on data.\n",
    "\n",
    "We are going to look at the prosper loan dataset.  This dataset shows a history of loans made by Prosper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## small file, start with this\n",
    "datafile = \"/data/prosper-loan/prosper-loan-data-simplified.csv\"\n",
    "## this is a large file\n",
    "#datafile = \"/data/prosper-loan/prosper-loan-data.csv.gz\"\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "data = spark.read. \\\n",
    "          option(\"header\", \"true\"). \\\n",
    "          option(\"inferSchema\", \"true\").  \\\n",
    "          csv(datafile)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(\"read {:,} records in {:,.2f} ms\".format(data.count(), (t2-t1)*1000))\n",
    "# schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## select a few columns \n",
    "## start with: 'LoanStatus',  'EmploymentStatus', 'CreditScore', 'StatedMonthlyIncome'\n",
    "## we add more later\n",
    "\n",
    "select_columns = ['LoanStatus', 'EmploymentStatus', 'CreditScore', 'StatedMonthlyIncome', 'ListingCategory']\n",
    "\n",
    "## Note : vector columns can only have Numbers, don't include Categorical columns here\n",
    "## And dfefinitely not 'LoanStatus'  (if you are curiuos include and see what happens!)\n",
    "vector_columns = [ 'EmpIndex', 'CreditScore', 'StatedMonthlyIncome', 'CategoryIndex']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Display\n",
    "\n",
    "prosper = data.select(select_columns)  \n",
    "prosper.printSchema()\n",
    "prosper.show()\n",
    "print (prosper.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop any NA values.  Using `dataframe.na.drop()`\n",
    "prosper_clean = prosper.na.drop()\n",
    "print(\"Original record count {:,}, cleaned records count {:,},  dropped {:,}\"\\\n",
    "      .format(prosper.count(), prosper_clean.count(), (prosper.count() - prosper_clean.count())))\n",
    "prosper_clean.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prosper_clean.groupBy('LoanStatus').count().show()\n",
    "prosper_clean.groupBy('EmploymentStatus').count().show()\n",
    "prosper_clean.groupBy('ListingCategory').count().show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> What does that say about the cardinality of these categorical columns? ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Converting Categorical columns \n",
    "\n",
    "Convert categorical columns to numeric.   \n",
    "Here let's convert **EmploymentStatus** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strIndexer_employment = StringIndexer(inputCol=\"EmploymentStatus\", outputCol=\"EmpIndex\")\n",
    "prosper_indexed = strIndexer_employment.fit(prosper_clean).transform(prosper_clean)\n",
    "\n",
    "strIndexer_category = StringIndexer(inputCol=\"ListingCategory\", outputCol=\"CategoryIndex\")\n",
    "prosper_indexed = strIndexer_category.fit(prosper_indexed).transform(prosper_indexed)\n",
    "\n",
    "prosper_indexed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build feature vectors using VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=vector_columns, outputCol=\"features\")\n",
    "feature_vector = assembler.transform(prosper_indexed)\n",
    "feature_vector = feature_vector.withColumn(\"label\", feature_vector[\"LoanStatus\"])\n",
    "feature_vector.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into training and test.\n",
    "\n",
    "We will split our the data up into training and test.  (You know the drill by now).\n",
    "\n",
    "**=> TODO: Split dataset into 70% training, 30% validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(training, test) =  feature_vector.randomSplit([.7,.3])\n",
    "print(\"training set = \" , training.count())\n",
    "print(\"testing set = \" , test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Create a RandomForest with numTrees=20  and maxBins=10000\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=???, maxBins=???)\n",
    "t1 = time.perf_counter()\n",
    "rf_model = rf.fit(training)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "## TODO : NOtice the time it took for training\n",
    "## Is it more or less than decision trees?\n",
    "print(\"traind on {:,} records using {:,} features in {:,.2f} ms\".\\\n",
    "      format(training.count(), len(vector_columns), (t2-t1)*1000))\n",
    "\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q : How many nodes the tree has? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = rf_model.transform(test)\n",
    "\n",
    "predictions2= predictions.drop('rawPrediction', 'probability')\n",
    "predictions2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model.\n",
    "\n",
    "Let us check to see how the model did, using accuracy as a measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy \",  accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 8: Improve Accuracy\n",
    "\n",
    "### Add more data\n",
    "In Step-1 change the 'datafile' to the full dataset.  \n",
    "And see how the accuracy above changes\n",
    "\n",
    "### Add more features\n",
    "Look at the schema of the full dataset.  Are there any columns you want to add"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
