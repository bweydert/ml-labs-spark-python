{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Learning: Prosper Loan Dataset\n",
    "\n",
    "A decision tree a learned set of rules that allows us to make decisions on data.\n",
    "\n",
    "We are going to look at the prosper loan dataset.  This dataset shows a history of loans made by Prosper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## small file, start with this\n",
    "datafile = \"/data/prosper-loan/prosper-loan-data-sample.csv\"\n",
    "## this is a large file\n",
    "#datafile = \"/data/prosper-loan/prosper-loan-data.csv.gz\"\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "data = spark.read. \\\n",
    "          option(\"header\", \"true\"). \\\n",
    "          option(\"inferSchema\", \"true\").  \\\n",
    "          csv(datafile)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(\"read {:,} records in {:,.2f} ms\".format(data.count(), (t2-t1)*1000))\n",
    "# schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : select a few columns \n",
    "## start with: 'LoanStatus',  'EmploymentStatus', 'CreditScore', 'StatedMonthlyIncome', 'ListingCategory'\n",
    "## we can add more later\n",
    "\n",
    "select_columns = ['LoanStatus', 'EmploymentStatus', 'CreditScore', '???', '???']\n",
    "\n",
    "## Note : vector columns can only have Numbers, don't include Categorical columns here\n",
    "## And dfefinitely not 'LoanStatus'  (if you are curiuos include and see what happens!)\n",
    "vector_columns = [ 'EmpIndex', 'CreditScore', 'StatedMonthlyIncome', 'CategoryIndex']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : Extract only the columns we are interested in\n",
    "## Hint : 'select_columns'\n",
    "prosper = data.select(???)  \n",
    "\n",
    "print (prosper.count())\n",
    "prosper.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO :  Drop any NA, null values.  \n",
    "## Hint : Using `.na.drop()`\n",
    "prosper_clean = prosper.na.???()\n",
    "\n",
    "print(\"Original record count {:,}, cleaned records count {:,},  dropped {:,}\"\\\n",
    "      .format(prosper.count(), prosper_clean.count(), (prosper.count() - prosper_clean.count())))\n",
    "prosper_clean.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some summary data\n",
    "\n",
    "**=> Q : What does that say about the cardinality of these categorical columns?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO : Look at some summaries\n",
    "## We are going to group counts by 'LoanStatus',  'EmploymentStatus' ,   'ListingCategory'\n",
    "\n",
    "prosper_clean.groupBy('LoanStatus').count().show()\n",
    "prosper_clean.groupBy('EmploymentStatus').count().show()\n",
    "prosper_clean.groupBy('???').count().show(60)\n",
    "\n",
    "## Question : What does that say about the cardinality of these categorical columns? *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Converting Categorical columns \n",
    "\n",
    "Convert categorical columns to numeric.   \n",
    "Here let's convert **EmploymentStatus** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : Create a StringIndexer with inputCol='EmploymentStatus'  and outputCol = 'EmpIndex'\n",
    "strIndexer_employment = StringIndexer(inputCol=\"???\", outputCol=\"???\")\n",
    "prosper_indexed = strIndexer_employment.fit(prosper_clean).transform(prosper_clean)\n",
    "\n",
    "prosper_indexed.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO : Create another StringIndexer,  inputCol='ListingCategory',   outputCol='CategoryIndex'\n",
    "strIndexer_category = StringIndexer(inputCol=\"ListingCategory\", outputCol=\"CategoryIndex\")\n",
    "prosper_indexed = strIndexer_category.fit(prosper_indexed).transform(prosper_indexed)\n",
    "\n",
    "prosper_indexed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build feature vectors using VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=vector_columns, outputCol=\"features\")\n",
    "feature_vector = assembler.transform(prosper_indexed)\n",
    "feature_vector = feature_vector.withColumn(\"label\", feature_vector[\"LoanStatus\"])\n",
    "feature_vector.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into training and test.\n",
    "\n",
    "We will split our the data up into training and test.  (You know the drill by now).\n",
    "\n",
    "**=> TODO: Split dataset into 70% training, 30% validation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO :  Split the data into 70% training and 30% test sets \n",
    "## Hint : 0.7   , 0.3\n",
    "(training, test) =  feature_vector.randomSplit([???,  ???])\n",
    "print(\"training set = \" , training.count())\n",
    "print(\"testing set = \" , test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Decision Tree\n",
    "** Q : How many nodes the tree has? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  TODO: Create a DecisionTree model with 5000 Maxbins\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxBins=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "## TODO : train with training data set\n",
    "## Hint : training\n",
    "tree_model = dt.fit(???)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "## TODO : Notice the time took to train\n",
    "print(\"traind on {:,} records using {:,} features in {:,.2f} ms\".\\\n",
    "      format(training.count(), len(vector_columns), (t2-t1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Print Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : Observe the output\n",
    "## how many nodes does the tree have?\n",
    "print(tree_model)\n",
    "print()\n",
    "print(tree_model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO : create predictions using test dataset\n",
    "## Hint : test\n",
    "predictions = tree_model.transform(???)\n",
    "\n",
    "predictions2= predictions.drop('rawPrediction', 'probability')\n",
    "predictions2.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model.\n",
    "\n",
    "Let us check to see how the model did, using accuracy as a measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"accuracy \",  accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 8: Improve Accuracy\n",
    "\n",
    "### Add more data\n",
    "In Step-1 change the 'datafile' to the full dataset.  \n",
    "And see how the accuracy above changes\n",
    "\n",
    "### Add more features\n",
    "Look at the schema of the full dataset.  Are there any columns you want to add"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
