{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines: Churn Analysis\n",
    "\n",
    "Let's look at a classification example in Spark MLLib.  We looked at the college admission before. We can look again at this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = spark.read.csv(\"/data/churn/telco.csv.gz\", header=True, inferSchema=True)\n",
    "\n",
    "prediction = ['Churn']\n",
    "categorical = ['gender',  'InternetService','Contract','PaymentMethod']\n",
    "categorical_index = ['gender_index',  'InternetService_index','Contract_index','PaymentMethod_index']\n",
    "\n",
    "\n",
    "columns = ['SeniorCitizen','PhoneService','Partner','Dependents','tenure','MultipleLines',\n",
    "           'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',\n",
    "           'StreamingTV','StreamingMovies','PaperlessBilling',\n",
    "           'MonthlyCharges','TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.select(categorical).show(5)\n",
    "dataset.select(prediction).show(5)\n",
    "dataset.select(columns).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Deal with Categorical Columns\n",
    "\n",
    "Let's deal with the categorical columns, including the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(categorical)\n",
    "dataset.select(categorical).show(5)\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid=\"keep\").\\\n",
    "            fit(dataset) for column in categorical ]\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"Churn\", outputCol=\"indexedLabel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build the Vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=columns + categorical_index, outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"indexedFeatures\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test.\n",
    "\n",
    "**=> Split into training/test with an 80/20 split ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split into training and test\n",
    "## TODO: create training and test with an 80/20 split\n",
    "(training, test) = dataset.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build the Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(labelCol=\"indexedLabel\", featuresCol=\"scaledFeatures\", maxIter=10, regParam=0.1)\n",
    "\n",
    "\n",
    "stages = indexers + [assembler, featureIndexer, labelIndexer, scaler, lsvc] \n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = pipeline.fit(training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the test set and get the predictions\n",
    "\n",
    "**=> TODO: Rename the label from \"admit\" to \"label\" **\n",
    "\n",
    "**=> TODO: Transform the test dataset to get predictions **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = lsvcModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: See the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='indexedLabel', rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)  #AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> What does AUC mean?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "predictions.groupBy('Churn').pivot('prediction', [0,1]).count().na.fill(0).orderBy('Churn').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> TODO: What is the meaning of the confusion matrix? **\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 9: Try running a prediction on your own data\n",
    "\n",
    "**=> Create a few rows in your own dataframe (start with pandas dataframe) ** \n",
    "\n",
    "**=> Run .transform from your model to see the results.**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
