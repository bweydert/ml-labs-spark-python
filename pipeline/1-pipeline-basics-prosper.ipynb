{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Spark Pipelines\n",
    "Let's build a simple Spark ML pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "print('Spark UI running on http://YOURIPADDRESS:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Load 'simplified' Propsper data\n",
    "And inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prosper = spark.read. \\\n",
    "          option(\"header\", \"true\"). \\\n",
    "          option(\"inferSchema\", \"true\").  \\\n",
    "          csv(\"/data/prosper-loan/prosper-loan-data-simplified.csv\")\n",
    "\n",
    "prosper.show()\n",
    "prosper.printSchema()\n",
    "print (prosper.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract a few columns\n",
    "Extract \n",
    "- LoanStatus\n",
    "- EmploymentStatus\n",
    "- CreditScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prosper2 = prosper.select(\"???\", \"???\", \"???\")\n",
    "prosper2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sanity check data and clean it\n",
    "use `describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prosper2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop any NA values.  Using `dataframe.na.drop()`\n",
    "prosper_clean = prosper2.???.???()\n",
    "prosper_clean.show()\n",
    "print(prosper_clean.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: StringIndexer for 'EmploymentStatus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint : inputCol = EmploymentStatus,   outputCol=EmploymentStatusIndex\n",
    "strIndexer_employment = StringIndexer(inputCol=\"???\", outputCol=\"???\")\n",
    "indexed1 = strIndexer_employment.fit(prosper_clean).transform(prosper_clean)\n",
    "indexed1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: One Hot Encoding for 'EmploymentStatus'\n",
    "Now that we have turned `EmploymentStatus` into a number, let's turn it into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint : inputCol = this is the outputcol of 'StringIndexer' \n",
    "#                   (strIndexer_employment.getOutputCol()  )\n",
    "encoder_employment = OneHotEncoder(inputCol=???, outputCol=\"EmploymentStatusVector\")\n",
    "encoded1 = encoder_employment.transform(indexed1)\n",
    "encoded1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create a pipeline\n",
    "Now we will do pipeline to do indexing and encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Hint : complete the following pipeline as follows\n",
    "##   StringINdexer : inputCol='EmploymnetStatus' --> outputCol='EmpIndex'\n",
    "##   OneHotEncoder : inputCol=strIndexer_employment.getOutputCol(), outputCol=\"EmpVector\"\n",
    "\n",
    "strIndexer_employment = StringIndexer(inputCol=\"???\", outputCol=\"???\")\n",
    "encoder_employment = OneHotEncoder(inputCol=???, outputCol=\"???\")\n",
    "pipeline = Pipeline(stages=(strIndexer_employment, encoder_employment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = pipeline.fit(prosper_clean)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prosper4 = model1.transform(prosper_clean)\n",
    "prosper4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Add Normalizer to CreditScore\n",
    "The FICO credit score ranges between 350 and 850.  Let's normalize this to the range of 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vector_assembler= VectorAssembler(inputCols=[\"CreditScore\"], outputCol=\"CreditScoreVec\")\n",
    "prosper_credit_score_vectorized = vector_assembler.transform(prosper_clean)\n",
    "prosper_credit_score_vectorized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "## Hint : set min=0 ,  max=100\n",
    "scaler_credit_score = MinMaxScaler(min=???, max=???, inputCol=\"CreditScoreVec\", outputCol=\"CreditScoreVecNormalized\")\n",
    "\n",
    "scaler_credit_score_model = scaler_credit_score.fit(prosper_credit_score_vectorized)\n",
    "propser5_scaled = scaler_credit_score_model.transform(prosper_credit_score_vectorized)\n",
    "propser5_scaled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## see the bottom score\n",
    "propser5_scaled.sort(\"CreditScore\", ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## see the top score\n",
    "propser5_scaled.sort(\"CreditScore\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: Final Pipeline Code\n",
    "Let's do a pipeline from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "prosper = spark.read. \\\n",
    "          option(\"header\", \"true\"). \\\n",
    "          option(\"inferSchema\", \"true\").  \\\n",
    "          csv(\"/data/prosper-loan/prosper-loan-data-simplified.csv\")\n",
    "\n",
    "prosper2 = prosper.select(\"LoanStatus\", \"EmploymentStatus\", \"CreditScore\")\n",
    "prosper_clean = prosper2.na.drop()\n",
    "\n",
    "\n",
    "\n",
    "## Hint\n",
    "##       StringIndexer (inputCol='EmploymentStatus',  outputCol='EmpIndex')\n",
    "##       OneHotEncoder(inputCol='EmpIndex',  outputCol='EmpVector')\n",
    "\n",
    "strIndexer_employment = StringIndexer(inputCol=\"???\", outputCol=\"???\")\n",
    "encoder_employment = OneHotEncoder(inputCol=\"???\", outputCol=\"???\")\n",
    "vector_assembler= VectorAssembler(inputCols=[\"CreditScore\"], outputCol=\"CreditScoreVec\")\n",
    "scaler_credit_score = MinMaxScaler(min=0, max=100, inputCol=\"CreditScoreVec\", outputCol=\"CreditScoreNormalized\")\n",
    "\n",
    "pipeline2 = Pipeline(stages=[strIndexer_employment, encoder_employment, vector_assembler, scaler_credit_score])\n",
    "\n",
    "## Hint : fit 'prosper_clean' data\n",
    "model2 = pipeline2.fit(???)\n",
    "\n",
    "## Hint : transform 'prosper_clean' data\n",
    "prosper_final = model2.transform(???)\n",
    "prosper_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
